{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification-Iris-using-Artificial-Neural-Network.ipynb",
      "provenance": [],
      "mount_file_id": "1Ngadv3tE34h8WmF_9dLVAWV48vCjGJ9s",
      "authorship_tag": "ABX9TyMW00upJMvgkamo1VZUaWt2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshalgurav/iris_neuralnetwork/blob/main/Classification_Iris_using_Artificial_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-rEQdwVmEA62"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to load dataset\n",
        "df=pd.read_csv('/content/drive/MyDrive/happymonk/iris.csv')"
      ],
      "metadata": {
        "id": "zhz9Nf8fEYOU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to see first 5 records\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gEoFSVvVE3o6",
        "outputId": "263de01c-8d48-42e7-b325-67076ddcaee6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width      species\n",
              "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
              "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
              "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
              "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
              "4           5.0          3.6           1.4          0.2  Iris-setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-03d8c6ae-f9cd-4087-8126-749ef57bfa1a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03d8c6ae-f9cd-4087-8126-749ef57bfa1a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-03d8c6ae-f9cd-4087-8126-749ef57bfa1a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-03d8c6ae-f9cd-4087-8126-749ef57bfa1a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#how many rows and columns\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n0qFLk2E6lT",
        "outputId": "4a322240-3798-4dd6-e404-b3417f622e40"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to check null values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru0rxI8YE9ZL",
        "outputId": "16822d92-b10f-44d8-c409-de44c7c4c8df"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sepal_length    0\n",
              "sepal_width     0\n",
              "petal_length    0\n",
              "petal_width     0\n",
              "species         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#visulization\n",
        "sns.heatmap(df.isnull())\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "lB5Tod70FWaf",
        "outputId": "df2cb3a8-4d8c-4b09-ea8d-f2ea7c176f07"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check datatype\n",
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrQh-BegFZS5",
        "outputId": "6d0fe001-8b25-424a-a934-d0e85aff85b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sepal_length    float64\n",
              "sepal_width     float64\n",
              "petal_length    float64\n",
              "petal_width     float64\n",
              "species          object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to check duplicate values\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P44eU9n5FbyH",
        "outputId": "c04dc05a-9d8d-44cc-d7ab-e47034250ebf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#how many samples of 1 and 0 in insuranceclaim output variable\n",
        "df[\"species\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgl0YEVnFegf",
        "outputId": "c776b94c-33b9-4afc-eb2e-d2682de477fd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Iris-setosa        50\n",
              "Iris-versicolor    50\n",
              "Iris-virginica     50\n",
              "Name: species, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#randomoversampling\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "#create object of RandomOverSampler\n",
        "ros=RandomOverSampler"
      ],
      "metadata": {
        "id": "qr1UFi77Fpp4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split data into 2 parts\n",
        "df_num=df.select_dtypes(['float64'])\n",
        "df_cat=df.select_dtypes('object')"
      ],
      "metadata": {
        "id": "BX9bhgKSFspR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "fBeeIucZFxl4",
        "outputId": "c4b59afa-da16-4a70-d1c0-68fe1725f240"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            species\n",
              "0       Iris-setosa\n",
              "1       Iris-setosa\n",
              "2       Iris-setosa\n",
              "3       Iris-setosa\n",
              "4       Iris-setosa\n",
              "..              ...\n",
              "145  Iris-virginica\n",
              "146  Iris-virginica\n",
              "147  Iris-virginica\n",
              "148  Iris-virginica\n",
              "149  Iris-virginica\n",
              "\n",
              "[150 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33e381fb-5089-4f4b-9dd2-d138d662adc5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33e381fb-5089-4f4b-9dd2-d138d662adc5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33e381fb-5089-4f4b-9dd2-d138d662adc5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33e381fb-5089-4f4b-9dd2-d138d662adc5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "C9Oat0aCF1K0",
        "outputId": "2f074f9f-6ddb-47fe-ad85-4d379ce15a5f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width\n",
              "0             5.1          3.5           1.4          0.2\n",
              "1             4.9          3.0           1.4          0.2\n",
              "2             4.7          3.2           1.3          0.2\n",
              "3             4.6          3.1           1.5          0.2\n",
              "4             5.0          3.6           1.4          0.2\n",
              "..            ...          ...           ...          ...\n",
              "145           6.7          3.0           5.2          2.3\n",
              "146           6.3          2.5           5.0          1.9\n",
              "147           6.5          3.0           5.2          2.0\n",
              "148           6.2          3.4           5.4          2.3\n",
              "149           5.9          3.0           5.1          1.8\n",
              "\n",
              "[150 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8df68fb-65ec-41b6-b377-6f9b4f0f0b07\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8df68fb-65ec-41b6-b377-6f9b4f0f0b07')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8df68fb-65ec-41b6-b377-6f9b4f0f0b07 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8df68fb-65ec-41b6-b377-6f9b4f0f0b07');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing #label encoder: text --> numeric\n",
        "le = preprocessing.LabelEncoder() #panggil LE\n",
        "le.fit(df_cat)\n",
        "df_cat= le.transform(df_cat) #ubah class yang masih text ke numeric\n",
        "\n",
        "df_cat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EplpJShEF4C0",
        "outputId": "310a65b1-9990-4819-e9d8-73a7978adbd2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le.transform ([\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA-PxQtuM0ZJ",
        "outputId": "bd144d06-7296-4aeb-d2ef-5de232ecf75b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "df_cat1 = to_categorical(df_cat) \n",
        "df_cat1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39jzuPm3M7AY",
        "outputId": "481f016d-f156-48bb-ccf9-49ae5d115c60"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_cat1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h8dD9g5M_fc",
        "outputId": "fb4d22b9-f2cb-4b11-a2c8-9aa1eb5c168d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "df_num1 = normalize(df_num,norm=\"l2\") \n",
        "\n",
        "df_num1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw-c85QiNMqd",
        "outputId": "b9e5a4e9-3d27-49a2-98fc-8cfa89e561ab"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_num1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g08kEnTuNjzO",
        "outputId": "d5995b69-112d-4868-af12-8211993ee9fb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.80377277, 0.55160877, 0.22064351, 0.0315205 ],\n",
              "       [0.82813287, 0.50702013, 0.23660939, 0.03380134],\n",
              "       [0.80533308, 0.54831188, 0.2227517 , 0.03426949],\n",
              "       [0.80003025, 0.53915082, 0.26087943, 0.03478392],\n",
              "       [0.790965  , 0.5694948 , 0.2214702 , 0.0316386 ],\n",
              "       [0.78417499, 0.5663486 , 0.2468699 , 0.05808704],\n",
              "       [0.78010936, 0.57660257, 0.23742459, 0.0508767 ],\n",
              "       [0.80218492, 0.54548574, 0.24065548, 0.0320874 ],\n",
              "       [0.80642366, 0.5315065 , 0.25658935, 0.03665562],\n",
              "       [0.81803119, 0.51752994, 0.25041771, 0.01669451],\n",
              "       [0.80373519, 0.55070744, 0.22325977, 0.02976797],\n",
              "       [0.786991  , 0.55745196, 0.26233033, 0.03279129],\n",
              "       [0.82307218, 0.51442011, 0.24006272, 0.01714734],\n",
              "       [0.8025126 , 0.55989251, 0.20529392, 0.01866308],\n",
              "       [0.81120865, 0.55945424, 0.16783627, 0.02797271],\n",
              "       [0.77381111, 0.59732787, 0.2036345 , 0.05430253],\n",
              "       [0.79428944, 0.57365349, 0.19121783, 0.05883625],\n",
              "       [0.80327412, 0.55126656, 0.22050662, 0.04725142],\n",
              "       [0.8068282 , 0.53788547, 0.24063297, 0.04246464],\n",
              "       [0.77964883, 0.58091482, 0.22930848, 0.0458617 ],\n",
              "       [0.8173379 , 0.51462016, 0.25731008, 0.03027177],\n",
              "       [0.78591858, 0.57017622, 0.23115252, 0.06164067],\n",
              "       [0.77577075, 0.60712493, 0.16864581, 0.03372916],\n",
              "       [0.80597792, 0.52151512, 0.26865931, 0.07901744],\n",
              "       [0.776114  , 0.54974742, 0.30721179, 0.03233808],\n",
              "       [0.82647451, 0.4958847 , 0.26447184, 0.03305898],\n",
              "       [0.79778206, 0.5424918 , 0.25529026, 0.06382256],\n",
              "       [0.80641965, 0.54278246, 0.23262105, 0.03101614],\n",
              "       [0.81609427, 0.5336001 , 0.21971769, 0.03138824],\n",
              "       [0.79524064, 0.54144043, 0.27072022, 0.03384003],\n",
              "       [0.80846584, 0.52213419, 0.26948861, 0.03368608],\n",
              "       [0.82225028, 0.51771314, 0.22840286, 0.06090743],\n",
              "       [0.76578311, 0.60379053, 0.22089897, 0.0147266 ],\n",
              "       [0.77867447, 0.59462414, 0.19820805, 0.02831544],\n",
              "       [0.81803119, 0.51752994, 0.25041771, 0.01669451],\n",
              "       [0.82512295, 0.52807869, 0.19802951, 0.03300492],\n",
              "       [0.82699754, 0.52627116, 0.19547215, 0.03007264],\n",
              "       [0.81803119, 0.51752994, 0.25041771, 0.01669451],\n",
              "       [0.80212413, 0.54690282, 0.23699122, 0.03646019],\n",
              "       [0.80779568, 0.53853046, 0.23758697, 0.03167826],\n",
              "       [0.80033301, 0.56023311, 0.20808658, 0.04801998],\n",
              "       [0.86093857, 0.44003527, 0.24871559, 0.0573959 ],\n",
              "       [0.78609038, 0.57170209, 0.23225397, 0.03573138],\n",
              "       [0.78889479, 0.55222635, 0.25244633, 0.09466737],\n",
              "       [0.76693897, 0.57144472, 0.28572236, 0.06015208],\n",
              "       [0.82210585, 0.51381615, 0.23978087, 0.05138162],\n",
              "       [0.77729093, 0.57915795, 0.24385598, 0.030482  ],\n",
              "       [0.79594782, 0.55370283, 0.24224499, 0.03460643],\n",
              "       [0.79837025, 0.55735281, 0.22595384, 0.03012718],\n",
              "       [0.81228363, 0.5361072 , 0.22743942, 0.03249135],\n",
              "       [0.76701103, 0.35063361, 0.51499312, 0.15340221],\n",
              "       [0.74549757, 0.37274878, 0.52417798, 0.17472599],\n",
              "       [0.75519285, 0.33928954, 0.53629637, 0.16417236],\n",
              "       [0.75384916, 0.31524601, 0.54825394, 0.17818253],\n",
              "       [0.7581754 , 0.32659863, 0.5365549 , 0.17496355],\n",
              "       [0.72232962, 0.35482858, 0.57026022, 0.16474184],\n",
              "       [0.72634846, 0.38046824, 0.54187901, 0.18446945],\n",
              "       [0.75916547, 0.37183615, 0.51127471, 0.15493173],\n",
              "       [0.76301853, 0.33526572, 0.53180079, 0.15029153],\n",
              "       [0.72460233, 0.37623583, 0.54345175, 0.19508524],\n",
              "       [0.76923077, 0.30769231, 0.53846154, 0.15384615],\n",
              "       [0.73923462, 0.37588201, 0.52623481, 0.187941  ],\n",
              "       [0.78892752, 0.28927343, 0.52595168, 0.13148792],\n",
              "       [0.73081412, 0.34743622, 0.56308629, 0.16772783],\n",
              "       [0.75911707, 0.3931142 , 0.48800383, 0.17622361],\n",
              "       [0.76945444, 0.35601624, 0.50531337, 0.16078153],\n",
              "       [0.70631892, 0.37838513, 0.5675777 , 0.18919257],\n",
              "       [0.75676497, 0.35228714, 0.53495455, 0.13047672],\n",
              "       [0.76444238, 0.27125375, 0.55483721, 0.18494574],\n",
              "       [0.76185188, 0.34011245, 0.53057542, 0.14964948],\n",
              "       [0.6985796 , 0.37889063, 0.56833595, 0.21312598],\n",
              "       [0.77011854, 0.35349703, 0.50499576, 0.16412362],\n",
              "       [0.74143307, 0.29421947, 0.57667016, 0.17653168],\n",
              "       [0.73659895, 0.33811099, 0.56754345, 0.14490471],\n",
              "       [0.76741698, 0.34773582, 0.51560829, 0.15588157],\n",
              "       [0.76785726, 0.34902603, 0.51190484, 0.16287881],\n",
              "       [0.76467269, 0.31486523, 0.53976896, 0.15743261],\n",
              "       [0.74088576, 0.33173989, 0.55289982, 0.18798594],\n",
              "       [0.73350949, 0.35452959, 0.55013212, 0.18337737],\n",
              "       [0.78667474, 0.35883409, 0.48304589, 0.13801311],\n",
              "       [0.76521855, 0.33391355, 0.52869645, 0.15304371],\n",
              "       [0.77242925, 0.33706004, 0.51963422, 0.14044168],\n",
              "       [0.76434981, 0.35581802, 0.51395936, 0.15814134],\n",
              "       [0.70779525, 0.31850786, 0.60162596, 0.1887454 ],\n",
              "       [0.69333409, 0.38518561, 0.57777841, 0.1925928 ],\n",
              "       [0.71524936, 0.40530797, 0.53643702, 0.19073316],\n",
              "       [0.75457341, 0.34913098, 0.52932761, 0.16893434],\n",
              "       [0.77530021, 0.28304611, 0.54147951, 0.15998258],\n",
              "       [0.72992443, 0.39103094, 0.53440896, 0.16944674],\n",
              "       [0.74714194, 0.33960997, 0.54337595, 0.17659719],\n",
              "       [0.72337118, 0.34195729, 0.57869695, 0.15782644],\n",
              "       [0.73260391, 0.36029701, 0.55245541, 0.1681386 ],\n",
              "       [0.76262994, 0.34186859, 0.52595168, 0.1577855 ],\n",
              "       [0.76986879, 0.35413965, 0.5081134 , 0.15397376],\n",
              "       [0.73544284, 0.35458851, 0.55158213, 0.1707278 ],\n",
              "       [0.73239618, 0.38547167, 0.53966034, 0.15418867],\n",
              "       [0.73446047, 0.37367287, 0.5411814 , 0.16750853],\n",
              "       [0.75728103, 0.3542121 , 0.52521104, 0.15878473],\n",
              "       [0.78258054, 0.38361791, 0.4603415 , 0.16879188],\n",
              "       [0.7431482 , 0.36505526, 0.5345452 , 0.16948994],\n",
              "       [0.65387747, 0.34250725, 0.62274045, 0.25947519],\n",
              "       [0.69052512, 0.32145135, 0.60718588, 0.22620651],\n",
              "       [0.71491405, 0.30207636, 0.59408351, 0.21145345],\n",
              "       [0.69276796, 0.31889319, 0.61579374, 0.1979337 ],\n",
              "       [0.68619022, 0.31670318, 0.61229281, 0.232249  ],\n",
              "       [0.70953708, 0.28008043, 0.61617694, 0.1960563 ],\n",
              "       [0.67054118, 0.34211284, 0.61580312, 0.23263673],\n",
              "       [0.71366557, 0.28351098, 0.61590317, 0.17597233],\n",
              "       [0.71414125, 0.26647062, 0.61821183, 0.19185884],\n",
              "       [0.69198788, 0.34599394, 0.58626751, 0.24027357],\n",
              "       [0.71562645, 0.3523084 , 0.56149152, 0.22019275],\n",
              "       [0.71576546, 0.30196356, 0.59274328, 0.21249287],\n",
              "       [0.71718148, 0.31640359, 0.58007326, 0.22148252],\n",
              "       [0.6925518 , 0.30375079, 0.60750157, 0.24300063],\n",
              "       [0.67767924, 0.32715549, 0.59589036, 0.28041899],\n",
              "       [0.69589887, 0.34794944, 0.57629125, 0.25008866],\n",
              "       [0.70610474, 0.3258945 , 0.59747324, 0.1955367 ],\n",
              "       [0.69299099, 0.34199555, 0.60299216, 0.19799743],\n",
              "       [0.70600618, 0.2383917 , 0.63265489, 0.21088496],\n",
              "       [0.72712585, 0.26661281, 0.60593821, 0.18178146],\n",
              "       [0.70558934, 0.32722984, 0.58287815, 0.23519645],\n",
              "       [0.68307923, 0.34153961, 0.59769433, 0.24395687],\n",
              "       [0.71486543, 0.25995106, 0.62202576, 0.18567933],\n",
              "       [0.73122464, 0.31338199, 0.56873028, 0.20892133],\n",
              "       [0.69595601, 0.3427843 , 0.59208198, 0.21813547],\n",
              "       [0.71529453, 0.31790868, 0.59607878, 0.17882363],\n",
              "       [0.72785195, 0.32870733, 0.56349829, 0.21131186],\n",
              "       [0.71171214, 0.35002236, 0.57170319, 0.21001342],\n",
              "       [0.69594002, 0.30447376, 0.60894751, 0.22835532],\n",
              "       [0.73089855, 0.30454106, 0.58877939, 0.1624219 ],\n",
              "       [0.72766159, 0.27533141, 0.59982915, 0.18683203],\n",
              "       [0.71578999, 0.34430405, 0.5798805 , 0.18121266],\n",
              "       [0.69417747, 0.30370264, 0.60740528, 0.2386235 ],\n",
              "       [0.72366005, 0.32162669, 0.58582004, 0.17230001],\n",
              "       [0.69385414, 0.29574111, 0.63698085, 0.15924521],\n",
              "       [0.73154399, 0.28501714, 0.57953485, 0.21851314],\n",
              "       [0.67017484, 0.36168166, 0.59571097, 0.2553047 ],\n",
              "       [0.69804799, 0.338117  , 0.59988499, 0.196326  ],\n",
              "       [0.71066905, 0.35533453, 0.56853524, 0.21320072],\n",
              "       [0.72415258, 0.32534391, 0.56672811, 0.22039426],\n",
              "       [0.69997037, 0.32386689, 0.58504986, 0.25073566],\n",
              "       [0.73337886, 0.32948905, 0.54206264, 0.24445962],\n",
              "       [0.69052512, 0.32145135, 0.60718588, 0.22620651],\n",
              "       [0.69193502, 0.32561648, 0.60035539, 0.23403685],\n",
              "       [0.68914871, 0.33943145, 0.58629069, 0.25714504],\n",
              "       [0.72155725, 0.32308533, 0.56001458, 0.24769876],\n",
              "       [0.72965359, 0.28954508, 0.57909015, 0.22005426],\n",
              "       [0.71653899, 0.3307103 , 0.57323119, 0.22047353],\n",
              "       [0.67467072, 0.36998072, 0.58761643, 0.25028107],\n",
              "       [0.69025916, 0.35097923, 0.5966647 , 0.21058754]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xtrain,xtest,ytrain,ytest = train_test_split(df_num1,df_cat1,test_size=0.30,random_state=1)"
      ],
      "metadata": {
        "id": "lGqJRwmMNnQO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2P_RbK2Nwn3",
        "outputId": "da9d1a8f-6cba-44a1-94eb-0f1d6d80968e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytest.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfoF10WXN1i3",
        "outputId": "c83d55e5-38d6-43b5-a0cc-98c9a569463b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(32, input_dim = 4, activation = 'relu')) \n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(32, activation = 'relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(16, activation = 'relu'))\n",
        "model.add(Dense(3, activation = 'softmax'))\n",
        "optimizer = Adam(lr=0.001)\n",
        "model.compile(optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "Model: \"sequential\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TsbKxaLN-II",
        "outputId": "3ad04529-fba2-4339-e5cf-1fb42e2dcf16"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 32)                160       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 3)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,507\n",
            "Trainable params: 21,507\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "jg0coJaFOBPB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(xtrain,ytrain,epochs=250,batch_size=10, verbose=1, validation_data=(xtest, ytest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Rv0gSWVOFsb",
        "outputId": "b85e6e58-fee0-41b7-b907-bed2d4015877"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "11/11 [==============================] - 2s 44ms/step - loss: 1.0933 - accuracy: 0.4381 - val_loss: 1.0818 - val_accuracy: 0.6000\n",
            "Epoch 2/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1.0713 - accuracy: 0.5143 - val_loss: 1.0524 - val_accuracy: 0.6000\n",
            "Epoch 3/250\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 1.0341 - accuracy: 0.6476 - val_loss: 0.9972 - val_accuracy: 0.6000\n",
            "Epoch 4/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.9620 - accuracy: 0.6286 - val_loss: 0.9005 - val_accuracy: 0.6000\n",
            "Epoch 5/250\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.8604 - accuracy: 0.6857 - val_loss: 0.7666 - val_accuracy: 0.6000\n",
            "Epoch 6/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.7113 - accuracy: 0.6857 - val_loss: 0.6423 - val_accuracy: 0.6000\n",
            "Epoch 7/250\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.6011 - accuracy: 0.6952 - val_loss: 0.5436 - val_accuracy: 0.6222\n",
            "Epoch 8/250\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.4967 - accuracy: 0.7619 - val_loss: 0.4640 - val_accuracy: 0.7778\n",
            "Epoch 9/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.4214 - accuracy: 0.8095 - val_loss: 0.4163 - val_accuracy: 0.7778\n",
            "Epoch 10/250\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.4099 - accuracy: 0.8381 - val_loss: 0.3593 - val_accuracy: 0.8889\n",
            "Epoch 11/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.3398 - accuracy: 0.8857 - val_loss: 0.3173 - val_accuracy: 0.9111\n",
            "Epoch 12/250\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.3174 - accuracy: 0.8762 - val_loss: 0.3346 - val_accuracy: 0.8222\n",
            "Epoch 13/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3754 - accuracy: 0.8286 - val_loss: 0.3210 - val_accuracy: 0.8444\n",
            "Epoch 14/250\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2972 - accuracy: 0.8857 - val_loss: 0.2521 - val_accuracy: 0.9333\n",
            "Epoch 15/250\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2899 - accuracy: 0.8762 - val_loss: 0.2522 - val_accuracy: 0.9333\n",
            "Epoch 16/250\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.2248 - accuracy: 0.9333 - val_loss: 0.1957 - val_accuracy: 0.9556\n",
            "Epoch 17/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.2036 - accuracy: 0.9333 - val_loss: 0.1626 - val_accuracy: 0.9556\n",
            "Epoch 18/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.1761 - accuracy: 0.9333 - val_loss: 0.1569 - val_accuracy: 0.9556\n",
            "Epoch 19/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2312 - accuracy: 0.9333 - val_loss: 0.1394 - val_accuracy: 0.9556\n",
            "Epoch 20/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.2376 - accuracy: 0.9143 - val_loss: 0.1368 - val_accuracy: 0.9556\n",
            "Epoch 21/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1619 - accuracy: 0.9524 - val_loss: 0.1243 - val_accuracy: 0.9556\n",
            "Epoch 22/250\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1771 - accuracy: 0.9619 - val_loss: 0.1170 - val_accuracy: 0.9556\n",
            "Epoch 23/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1866 - accuracy: 0.9429 - val_loss: 0.1315 - val_accuracy: 0.9556\n",
            "Epoch 24/250\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.1618 - accuracy: 0.9238 - val_loss: 0.1205 - val_accuracy: 0.9778\n",
            "Epoch 25/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1493 - accuracy: 0.9524 - val_loss: 0.1113 - val_accuracy: 0.9778\n",
            "Epoch 26/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.1492 - accuracy: 0.9524 - val_loss: 0.1555 - val_accuracy: 0.9333\n",
            "Epoch 27/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1956 - accuracy: 0.9429 - val_loss: 0.3073 - val_accuracy: 0.8444\n",
            "Epoch 28/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2137 - accuracy: 0.9333 - val_loss: 0.1112 - val_accuracy: 0.9556\n",
            "Epoch 29/250\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.1717 - accuracy: 0.9238 - val_loss: 0.1188 - val_accuracy: 0.9556\n",
            "Epoch 30/250\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.1392 - accuracy: 0.9524 - val_loss: 0.1033 - val_accuracy: 0.9556\n",
            "Epoch 31/250\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1505 - accuracy: 0.9429 - val_loss: 0.0984 - val_accuracy: 0.9556\n",
            "Epoch 32/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.1999 - accuracy: 0.9333 - val_loss: 0.1653 - val_accuracy: 0.9556\n",
            "Epoch 33/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.1412 - accuracy: 0.9429 - val_loss: 0.0996 - val_accuracy: 0.9778\n",
            "Epoch 34/250\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.1582 - accuracy: 0.9429 - val_loss: 0.1061 - val_accuracy: 0.9556\n",
            "Epoch 35/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1238 - accuracy: 0.9810 - val_loss: 0.0967 - val_accuracy: 0.9778\n",
            "Epoch 36/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1747 - accuracy: 0.9429 - val_loss: 0.0931 - val_accuracy: 0.9556\n",
            "Epoch 37/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.1201 - accuracy: 0.9429 - val_loss: 0.0882 - val_accuracy: 0.9556\n",
            "Epoch 38/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1614 - accuracy: 0.9619 - val_loss: 0.0991 - val_accuracy: 0.9778\n",
            "Epoch 39/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1344 - accuracy: 0.9524 - val_loss: 0.0939 - val_accuracy: 0.9556\n",
            "Epoch 40/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1475 - accuracy: 0.9429 - val_loss: 0.0936 - val_accuracy: 0.9778\n",
            "Epoch 41/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.1239 - accuracy: 0.9619 - val_loss: 0.0947 - val_accuracy: 0.9778\n",
            "Epoch 42/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1229 - accuracy: 0.9619 - val_loss: 0.0923 - val_accuracy: 0.9778\n",
            "Epoch 43/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.1168 - accuracy: 0.9619 - val_loss: 0.0916 - val_accuracy: 0.9556\n",
            "Epoch 44/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1360 - accuracy: 0.9619 - val_loss: 0.1391 - val_accuracy: 0.9556\n",
            "Epoch 45/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1770 - accuracy: 0.9143 - val_loss: 0.1117 - val_accuracy: 0.9778\n",
            "Epoch 46/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1382 - accuracy: 0.9619 - val_loss: 0.1275 - val_accuracy: 0.9556\n",
            "Epoch 47/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1229 - accuracy: 0.9524 - val_loss: 0.1006 - val_accuracy: 0.9778\n",
            "Epoch 48/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.1159 - accuracy: 0.9524 - val_loss: 0.1591 - val_accuracy: 0.9333\n",
            "Epoch 49/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.1359 - accuracy: 0.9524 - val_loss: 0.1023 - val_accuracy: 0.9778\n",
            "Epoch 50/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1197 - accuracy: 0.9619 - val_loss: 0.0876 - val_accuracy: 0.9556\n",
            "Epoch 51/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1344 - accuracy: 0.9619 - val_loss: 0.0993 - val_accuracy: 0.9556\n",
            "Epoch 52/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.1174 - accuracy: 0.9524 - val_loss: 0.0888 - val_accuracy: 0.9778\n",
            "Epoch 53/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1160 - accuracy: 0.9619 - val_loss: 0.0883 - val_accuracy: 0.9778\n",
            "Epoch 54/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1207 - accuracy: 0.9524 - val_loss: 0.0933 - val_accuracy: 0.9778\n",
            "Epoch 55/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1038 - accuracy: 0.9619 - val_loss: 0.0811 - val_accuracy: 0.9778\n",
            "Epoch 56/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.1359 - accuracy: 0.9524 - val_loss: 0.0798 - val_accuracy: 0.9556\n",
            "Epoch 57/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1670 - accuracy: 0.9238 - val_loss: 0.1716 - val_accuracy: 0.9111\n",
            "Epoch 58/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2178 - accuracy: 0.9333 - val_loss: 0.1176 - val_accuracy: 0.9778\n",
            "Epoch 59/250\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.1327 - accuracy: 0.9524 - val_loss: 0.1592 - val_accuracy: 0.9556\n",
            "Epoch 60/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.1891 - accuracy: 0.9333 - val_loss: 0.1045 - val_accuracy: 0.9778\n",
            "Epoch 61/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.2209 - accuracy: 0.9238 - val_loss: 0.0937 - val_accuracy: 0.9556\n",
            "Epoch 62/250\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.1344 - accuracy: 0.9619 - val_loss: 0.0959 - val_accuracy: 0.9556\n",
            "Epoch 63/250\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.1296 - accuracy: 0.9429 - val_loss: 0.0953 - val_accuracy: 0.9778\n",
            "Epoch 64/250\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1032 - accuracy: 0.9524 - val_loss: 0.0900 - val_accuracy: 0.9556\n",
            "Epoch 65/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0920 - accuracy: 0.9714 - val_loss: 0.0804 - val_accuracy: 0.9556\n",
            "Epoch 66/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1109 - accuracy: 0.9714 - val_loss: 0.0969 - val_accuracy: 0.9556\n",
            "Epoch 67/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.1318 - accuracy: 0.9714 - val_loss: 0.0840 - val_accuracy: 0.9778\n",
            "Epoch 68/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1124 - accuracy: 0.9619 - val_loss: 0.1257 - val_accuracy: 0.9556\n",
            "Epoch 69/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.1219 - accuracy: 0.9524 - val_loss: 0.0913 - val_accuracy: 0.9778\n",
            "Epoch 70/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1517 - accuracy: 0.9429 - val_loss: 0.0865 - val_accuracy: 0.9778\n",
            "Epoch 71/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0903 - accuracy: 0.9810 - val_loss: 0.0898 - val_accuracy: 0.9778\n",
            "Epoch 72/250\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.1289 - accuracy: 0.9429 - val_loss: 0.1349 - val_accuracy: 0.9556\n",
            "Epoch 73/250\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.1548 - accuracy: 0.9238 - val_loss: 0.0860 - val_accuracy: 0.9778\n",
            "Epoch 74/250\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1136 - accuracy: 0.9619 - val_loss: 0.0822 - val_accuracy: 0.9556\n",
            "Epoch 75/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1113 - accuracy: 0.9714 - val_loss: 0.0937 - val_accuracy: 0.9778\n",
            "Epoch 76/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1582 - accuracy: 0.9333 - val_loss: 0.0958 - val_accuracy: 0.9778\n",
            "Epoch 77/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1346 - accuracy: 0.9524 - val_loss: 0.0924 - val_accuracy: 0.9778\n",
            "Epoch 78/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.1202 - accuracy: 0.9619 - val_loss: 0.1373 - val_accuracy: 0.9556\n",
            "Epoch 79/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1181 - accuracy: 0.9524 - val_loss: 0.1170 - val_accuracy: 0.9556\n",
            "Epoch 80/250\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.1191 - accuracy: 0.9619 - val_loss: 0.0955 - val_accuracy: 0.9778\n",
            "Epoch 81/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.1161 - accuracy: 0.9524 - val_loss: 0.0742 - val_accuracy: 0.9778\n",
            "Epoch 82/250\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.1713 - accuracy: 0.9333 - val_loss: 0.1615 - val_accuracy: 0.9111\n",
            "Epoch 83/250\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2185 - accuracy: 0.8857 - val_loss: 0.0820 - val_accuracy: 0.9556\n",
            "Epoch 84/250\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.1188 - accuracy: 0.9619 - val_loss: 0.1158 - val_accuracy: 0.9556\n",
            "Epoch 85/250\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.1090 - accuracy: 0.9619 - val_loss: 0.1389 - val_accuracy: 0.9556\n",
            "Epoch 86/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1143 - accuracy: 0.9429 - val_loss: 0.1220 - val_accuracy: 0.9556\n",
            "Epoch 87/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0989 - accuracy: 0.9619 - val_loss: 0.0965 - val_accuracy: 0.9778\n",
            "Epoch 88/250\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.1377 - accuracy: 0.9524 - val_loss: 0.1038 - val_accuracy: 0.9556\n",
            "Epoch 89/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.1302 - accuracy: 0.9619 - val_loss: 0.1832 - val_accuracy: 0.9111\n",
            "Epoch 90/250\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.1382 - accuracy: 0.9429 - val_loss: 0.0888 - val_accuracy: 0.9778\n",
            "Epoch 91/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.1958 - accuracy: 0.9238 - val_loss: 0.0824 - val_accuracy: 0.9778\n",
            "Epoch 92/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1305 - accuracy: 0.9524 - val_loss: 0.1212 - val_accuracy: 0.9556\n",
            "Epoch 93/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1657 - accuracy: 0.9429 - val_loss: 0.0818 - val_accuracy: 0.9778\n",
            "Epoch 94/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1231 - accuracy: 0.9524 - val_loss: 0.0846 - val_accuracy: 0.9778\n",
            "Epoch 95/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.1198 - accuracy: 0.9524 - val_loss: 0.0802 - val_accuracy: 0.9778\n",
            "Epoch 96/250\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.1124 - accuracy: 0.9619 - val_loss: 0.0871 - val_accuracy: 0.9778\n",
            "Epoch 97/250\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.1565 - accuracy: 0.9524 - val_loss: 0.0913 - val_accuracy: 0.9778\n",
            "Epoch 98/250\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.1735 - accuracy: 0.9524 - val_loss: 0.0891 - val_accuracy: 0.9778\n",
            "Epoch 99/250\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.1264 - accuracy: 0.9619 - val_loss: 0.0921 - val_accuracy: 0.9556\n",
            "Epoch 100/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1145 - accuracy: 0.9619 - val_loss: 0.0898 - val_accuracy: 0.9778\n",
            "Epoch 101/250\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.1244 - accuracy: 0.9429 - val_loss: 0.0835 - val_accuracy: 0.9778\n",
            "Epoch 102/250\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.1201 - accuracy: 0.9524 - val_loss: 0.0779 - val_accuracy: 0.9778\n",
            "Epoch 103/250\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.1485 - accuracy: 0.9524 - val_loss: 0.0766 - val_accuracy: 0.9778\n",
            "Epoch 104/250\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.1222 - accuracy: 0.9333 - val_loss: 0.0773 - val_accuracy: 0.9778\n",
            "Epoch 105/250\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.1104 - accuracy: 0.9524 - val_loss: 0.1098 - val_accuracy: 0.9556\n",
            "Epoch 106/250\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.1569 - accuracy: 0.9238 - val_loss: 0.0746 - val_accuracy: 0.9778\n",
            "Epoch 107/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.1916 - accuracy: 0.9143 - val_loss: 0.0824 - val_accuracy: 0.9778\n",
            "Epoch 108/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.1499 - accuracy: 0.9333 - val_loss: 0.0841 - val_accuracy: 0.9778\n",
            "Epoch 109/250\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.1179 - accuracy: 0.9619 - val_loss: 0.0826 - val_accuracy: 0.9778\n",
            "Epoch 110/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.0896 - accuracy: 0.9714 - val_loss: 0.0754 - val_accuracy: 0.9778\n",
            "Epoch 111/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.1057 - accuracy: 0.9619 - val_loss: 0.0720 - val_accuracy: 0.9778\n",
            "Epoch 112/250\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.1026 - accuracy: 0.9714 - val_loss: 0.0702 - val_accuracy: 0.9778\n",
            "Epoch 113/250\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.1017 - accuracy: 0.9619 - val_loss: 0.0877 - val_accuracy: 0.9778\n",
            "Epoch 114/250\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.1163 - accuracy: 0.9524 - val_loss: 0.0820 - val_accuracy: 0.9778\n",
            "Epoch 115/250\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.1065 - accuracy: 0.9619 - val_loss: 0.0671 - val_accuracy: 0.9778\n",
            "Epoch 116/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.1201 - accuracy: 0.9524 - val_loss: 0.0821 - val_accuracy: 0.9778\n",
            "Epoch 117/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.1150 - accuracy: 0.9429 - val_loss: 0.0890 - val_accuracy: 0.9556\n",
            "Epoch 118/250\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.1526 - accuracy: 0.9429 - val_loss: 0.0747 - val_accuracy: 0.9778\n",
            "Epoch 119/250\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1543 - accuracy: 0.9429 - val_loss: 0.0817 - val_accuracy: 0.9778\n",
            "Epoch 120/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0938 - accuracy: 0.9714 - val_loss: 0.0897 - val_accuracy: 0.9778\n",
            "Epoch 121/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0957 - accuracy: 0.9619 - val_loss: 0.0722 - val_accuracy: 0.9778\n",
            "Epoch 122/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0790 - accuracy: 0.9714 - val_loss: 0.0679 - val_accuracy: 0.9556\n",
            "Epoch 123/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1172 - accuracy: 0.9619 - val_loss: 0.0636 - val_accuracy: 0.9778\n",
            "Epoch 124/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1981 - accuracy: 0.9333 - val_loss: 0.0996 - val_accuracy: 0.9556\n",
            "Epoch 125/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1056 - accuracy: 0.9810 - val_loss: 0.1291 - val_accuracy: 0.9556\n",
            "Epoch 126/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.1353 - accuracy: 0.9524 - val_loss: 0.1251 - val_accuracy: 0.9556\n",
            "Epoch 127/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1119 - accuracy: 0.9619 - val_loss: 0.0888 - val_accuracy: 0.9778\n",
            "Epoch 128/250\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.1028 - accuracy: 0.9619 - val_loss: 0.0801 - val_accuracy: 0.9778\n",
            "Epoch 129/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0838 - accuracy: 0.9619 - val_loss: 0.0892 - val_accuracy: 0.9778\n",
            "Epoch 130/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0968 - accuracy: 0.9619 - val_loss: 0.0901 - val_accuracy: 0.9778\n",
            "Epoch 131/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1037 - accuracy: 0.9524 - val_loss: 0.0599 - val_accuracy: 0.9778\n",
            "Epoch 132/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.1010 - accuracy: 0.9619 - val_loss: 0.0624 - val_accuracy: 0.9778\n",
            "Epoch 133/250\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.1079 - accuracy: 0.9524 - val_loss: 0.0686 - val_accuracy: 0.9778\n",
            "Epoch 134/250\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.1194 - accuracy: 0.9619 - val_loss: 0.0662 - val_accuracy: 0.9778\n",
            "Epoch 135/250\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.1015 - accuracy: 0.9619 - val_loss: 0.0705 - val_accuracy: 0.9778\n",
            "Epoch 136/250\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.0901 - accuracy: 0.9714 - val_loss: 0.0626 - val_accuracy: 0.9778\n",
            "Epoch 137/250\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.1159 - accuracy: 0.9429 - val_loss: 0.0630 - val_accuracy: 0.9778\n",
            "Epoch 138/250\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.1069 - accuracy: 0.9619 - val_loss: 0.0621 - val_accuracy: 0.9778\n",
            "Epoch 139/250\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.1230 - accuracy: 0.9524 - val_loss: 0.0665 - val_accuracy: 0.9778\n",
            "Epoch 140/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1133 - accuracy: 0.9524 - val_loss: 0.0893 - val_accuracy: 0.9556\n",
            "Epoch 141/250\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.1020 - accuracy: 0.9714 - val_loss: 0.0693 - val_accuracy: 0.9778\n",
            "Epoch 142/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0795 - accuracy: 0.9810 - val_loss: 0.0697 - val_accuracy: 0.9778\n",
            "Epoch 143/250\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0930 - accuracy: 0.9619 - val_loss: 0.0755 - val_accuracy: 0.9778\n",
            "Epoch 144/250\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1342 - accuracy: 0.9524 - val_loss: 0.0622 - val_accuracy: 0.9778\n",
            "Epoch 145/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1103 - accuracy: 0.9429 - val_loss: 0.0634 - val_accuracy: 0.9778\n",
            "Epoch 146/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0968 - accuracy: 0.9619 - val_loss: 0.0680 - val_accuracy: 0.9778\n",
            "Epoch 147/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1221 - accuracy: 0.9524 - val_loss: 0.1035 - val_accuracy: 0.9778\n",
            "Epoch 148/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1331 - accuracy: 0.9619 - val_loss: 0.0847 - val_accuracy: 0.9778\n",
            "Epoch 149/250\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.1198 - accuracy: 0.9619 - val_loss: 0.0824 - val_accuracy: 0.9778\n",
            "Epoch 150/250\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0984 - accuracy: 0.9714 - val_loss: 0.0713 - val_accuracy: 0.9778\n",
            "Epoch 151/250\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.1154 - accuracy: 0.9524 - val_loss: 0.0834 - val_accuracy: 0.9778\n",
            "Epoch 152/250\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.1117 - accuracy: 0.9619 - val_loss: 0.0733 - val_accuracy: 0.9778\n",
            "Epoch 153/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0807 - accuracy: 0.9810 - val_loss: 0.0678 - val_accuracy: 0.9778\n",
            "Epoch 154/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0947 - accuracy: 0.9714 - val_loss: 0.0669 - val_accuracy: 0.9778\n",
            "Epoch 155/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.1080 - accuracy: 0.9714 - val_loss: 0.0758 - val_accuracy: 0.9778\n",
            "Epoch 156/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1529 - accuracy: 0.9429 - val_loss: 0.0903 - val_accuracy: 0.9556\n",
            "Epoch 157/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1606 - accuracy: 0.9333 - val_loss: 0.0911 - val_accuracy: 0.9556\n",
            "Epoch 158/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1723 - accuracy: 0.9524 - val_loss: 0.0760 - val_accuracy: 0.9778\n",
            "Epoch 159/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.1147 - accuracy: 0.9714 - val_loss: 0.0935 - val_accuracy: 0.9556\n",
            "Epoch 160/250\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.0877 - accuracy: 0.9619 - val_loss: 0.1320 - val_accuracy: 0.9111\n",
            "Epoch 161/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1343 - accuracy: 0.9429 - val_loss: 0.0806 - val_accuracy: 0.9556\n",
            "Epoch 162/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1301 - accuracy: 0.9524 - val_loss: 0.0728 - val_accuracy: 0.9778\n",
            "Epoch 163/250\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.2434 - accuracy: 0.8952 - val_loss: 0.2398 - val_accuracy: 0.8889\n",
            "Epoch 164/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.1408 - accuracy: 0.9619 - val_loss: 0.1628 - val_accuracy: 0.9333\n",
            "Epoch 165/250\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.1207 - accuracy: 0.9429 - val_loss: 0.1162 - val_accuracy: 0.9556\n",
            "Epoch 166/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1123 - accuracy: 0.9714 - val_loss: 0.0812 - val_accuracy: 0.9778\n",
            "Epoch 167/250\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.1054 - accuracy: 0.9524 - val_loss: 0.0758 - val_accuracy: 0.9778\n",
            "Epoch 168/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1235 - accuracy: 0.9619 - val_loss: 0.0697 - val_accuracy: 0.9778\n",
            "Epoch 169/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1202 - accuracy: 0.9429 - val_loss: 0.0666 - val_accuracy: 0.9778\n",
            "Epoch 170/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0857 - accuracy: 0.9619 - val_loss: 0.0794 - val_accuracy: 0.9778\n",
            "Epoch 171/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0600 - accuracy: 0.9810 - val_loss: 0.0602 - val_accuracy: 0.9778\n",
            "Epoch 172/250\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0783 - accuracy: 0.9810 - val_loss: 0.0573 - val_accuracy: 0.9778\n",
            "Epoch 173/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.1095 - accuracy: 0.9714 - val_loss: 0.0581 - val_accuracy: 0.9556\n",
            "Epoch 174/250\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.1221 - accuracy: 0.9619 - val_loss: 0.0653 - val_accuracy: 0.9778\n",
            "Epoch 175/250\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.1004 - accuracy: 0.9619 - val_loss: 0.0613 - val_accuracy: 0.9778\n",
            "Epoch 176/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.1290 - accuracy: 0.9619 - val_loss: 0.0696 - val_accuracy: 0.9778\n",
            "Epoch 177/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0915 - accuracy: 0.9619 - val_loss: 0.1137 - val_accuracy: 0.9556\n",
            "Epoch 178/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.1440 - accuracy: 0.9619 - val_loss: 0.0744 - val_accuracy: 0.9778\n",
            "Epoch 179/250\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0989 - accuracy: 0.9714 - val_loss: 0.1009 - val_accuracy: 0.9778\n",
            "Epoch 180/250\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.1026 - accuracy: 0.9524 - val_loss: 0.0810 - val_accuracy: 0.9778\n",
            "Epoch 181/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.1049 - accuracy: 0.9524 - val_loss: 0.0695 - val_accuracy: 0.9778\n",
            "Epoch 182/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.1006 - accuracy: 0.9619 - val_loss: 0.0687 - val_accuracy: 0.9778\n",
            "Epoch 183/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0953 - accuracy: 0.9524 - val_loss: 0.0674 - val_accuracy: 0.9778\n",
            "Epoch 184/250\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.1006 - accuracy: 0.9619 - val_loss: 0.0707 - val_accuracy: 0.9778\n",
            "Epoch 185/250\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.0935 - accuracy: 0.9714 - val_loss: 0.1288 - val_accuracy: 0.9333\n",
            "Epoch 186/250\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.0781 - accuracy: 0.9714 - val_loss: 0.0844 - val_accuracy: 0.9778\n",
            "Epoch 187/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1023 - accuracy: 0.9524 - val_loss: 0.0718 - val_accuracy: 0.9778\n",
            "Epoch 188/250\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0936 - accuracy: 0.9714 - val_loss: 0.0656 - val_accuracy: 0.9778\n",
            "Epoch 189/250\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1029 - accuracy: 0.9619 - val_loss: 0.0781 - val_accuracy: 0.9778\n",
            "Epoch 190/250\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1206 - accuracy: 0.9524 - val_loss: 0.0672 - val_accuracy: 0.9778\n",
            "Epoch 191/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1061 - accuracy: 0.9524 - val_loss: 0.0730 - val_accuracy: 0.9778\n",
            "Epoch 192/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1182 - accuracy: 0.9524 - val_loss: 0.0969 - val_accuracy: 0.9556\n",
            "Epoch 193/250\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9810 - val_loss: 0.0794 - val_accuracy: 0.9778\n",
            "Epoch 194/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0995 - accuracy: 0.9714 - val_loss: 0.0664 - val_accuracy: 0.9556\n",
            "Epoch 195/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.9714 - val_loss: 0.0630 - val_accuracy: 0.9778\n",
            "Epoch 196/250\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1137 - accuracy: 0.9619 - val_loss: 0.0623 - val_accuracy: 0.9778\n",
            "Epoch 197/250\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0879 - accuracy: 0.9714 - val_loss: 0.0700 - val_accuracy: 0.9778\n",
            "Epoch 198/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1010 - accuracy: 0.9714 - val_loss: 0.0607 - val_accuracy: 0.9778\n",
            "Epoch 199/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0841 - accuracy: 0.9619 - val_loss: 0.0758 - val_accuracy: 0.9778\n",
            "Epoch 200/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0796 - accuracy: 0.9714 - val_loss: 0.0606 - val_accuracy: 0.9778\n",
            "Epoch 201/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1039 - accuracy: 0.9619 - val_loss: 0.0591 - val_accuracy: 0.9778\n",
            "Epoch 202/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0721 - accuracy: 0.9714 - val_loss: 0.0568 - val_accuracy: 0.9778\n",
            "Epoch 203/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1213 - accuracy: 0.9524 - val_loss: 0.0653 - val_accuracy: 0.9778\n",
            "Epoch 204/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0909 - accuracy: 0.9619 - val_loss: 0.0598 - val_accuracy: 0.9778\n",
            "Epoch 205/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1189 - accuracy: 0.9714 - val_loss: 0.0781 - val_accuracy: 0.9778\n",
            "Epoch 206/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1134 - accuracy: 0.9524 - val_loss: 0.0939 - val_accuracy: 0.9778\n",
            "Epoch 207/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0996 - accuracy: 0.9619 - val_loss: 0.0861 - val_accuracy: 0.9556\n",
            "Epoch 208/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1666 - accuracy: 0.9524 - val_loss: 0.1042 - val_accuracy: 0.9556\n",
            "Epoch 209/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1380 - accuracy: 0.9429 - val_loss: 0.0903 - val_accuracy: 0.9778\n",
            "Epoch 210/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1067 - accuracy: 0.9810 - val_loss: 0.1754 - val_accuracy: 0.8889\n",
            "Epoch 211/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1212 - accuracy: 0.9524 - val_loss: 0.0891 - val_accuracy: 0.9778\n",
            "Epoch 212/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1057 - accuracy: 0.9619 - val_loss: 0.0882 - val_accuracy: 0.9778\n",
            "Epoch 213/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1000 - accuracy: 0.9714 - val_loss: 0.0996 - val_accuracy: 0.9556\n",
            "Epoch 214/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0894 - accuracy: 0.9714 - val_loss: 0.0717 - val_accuracy: 0.9778\n",
            "Epoch 215/250\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1010 - accuracy: 0.9524 - val_loss: 0.0654 - val_accuracy: 0.9778\n",
            "Epoch 216/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0963 - accuracy: 0.9714 - val_loss: 0.0769 - val_accuracy: 0.9778\n",
            "Epoch 217/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0867 - accuracy: 0.9810 - val_loss: 0.1428 - val_accuracy: 0.9778\n",
            "Epoch 218/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0991 - accuracy: 0.9619 - val_loss: 0.1271 - val_accuracy: 0.9111\n",
            "Epoch 219/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1184 - accuracy: 0.9619 - val_loss: 0.0839 - val_accuracy: 0.9778\n",
            "Epoch 220/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0999 - accuracy: 0.9714 - val_loss: 0.0703 - val_accuracy: 0.9778\n",
            "Epoch 221/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0997 - accuracy: 0.9714 - val_loss: 0.0973 - val_accuracy: 0.9778\n",
            "Epoch 222/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1015 - accuracy: 0.9619 - val_loss: 0.0709 - val_accuracy: 0.9778\n",
            "Epoch 223/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1342 - accuracy: 0.9619 - val_loss: 0.0775 - val_accuracy: 0.9778\n",
            "Epoch 224/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0839 - accuracy: 0.9714 - val_loss: 0.0711 - val_accuracy: 0.9778\n",
            "Epoch 225/250\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1107 - accuracy: 0.9619 - val_loss: 0.0726 - val_accuracy: 0.9778\n",
            "Epoch 226/250\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1176 - accuracy: 0.9619 - val_loss: 0.1102 - val_accuracy: 0.9556\n",
            "Epoch 227/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1296 - accuracy: 0.9619 - val_loss: 0.1075 - val_accuracy: 0.9778\n",
            "Epoch 228/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0858 - accuracy: 0.9714 - val_loss: 0.0884 - val_accuracy: 0.9778\n",
            "Epoch 229/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1109 - accuracy: 0.9619 - val_loss: 0.0913 - val_accuracy: 0.9556\n",
            "Epoch 230/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0887 - accuracy: 0.9714 - val_loss: 0.0872 - val_accuracy: 0.9778\n",
            "Epoch 231/250\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9714 - val_loss: 0.0811 - val_accuracy: 0.9778\n",
            "Epoch 232/250\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1083 - accuracy: 0.9619 - val_loss: 0.0907 - val_accuracy: 0.9778\n",
            "Epoch 233/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0899 - accuracy: 0.9714 - val_loss: 0.0748 - val_accuracy: 0.9778\n",
            "Epoch 234/250\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0762 - accuracy: 0.9714 - val_loss: 0.0912 - val_accuracy: 0.9778\n",
            "Epoch 235/250\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1042 - accuracy: 0.9619 - val_loss: 0.0714 - val_accuracy: 0.9778\n",
            "Epoch 236/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1264 - accuracy: 0.9619 - val_loss: 0.0505 - val_accuracy: 1.0000\n",
            "Epoch 237/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1404 - accuracy: 0.9524 - val_loss: 0.1253 - val_accuracy: 0.9333\n",
            "Epoch 238/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1200 - accuracy: 0.9524 - val_loss: 0.1813 - val_accuracy: 0.9333\n",
            "Epoch 239/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1102 - accuracy: 0.9714 - val_loss: 0.0988 - val_accuracy: 0.9556\n",
            "Epoch 240/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1090 - accuracy: 0.9619 - val_loss: 0.0838 - val_accuracy: 0.9778\n",
            "Epoch 241/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0988 - accuracy: 0.9619 - val_loss: 0.0928 - val_accuracy: 0.9778\n",
            "Epoch 242/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1070 - accuracy: 0.9619 - val_loss: 0.0706 - val_accuracy: 0.9778\n",
            "Epoch 243/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1040 - accuracy: 0.9524 - val_loss: 0.0648 - val_accuracy: 0.9778\n",
            "Epoch 244/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0955 - accuracy: 0.9619 - val_loss: 0.0843 - val_accuracy: 0.9778\n",
            "Epoch 245/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0889 - accuracy: 0.9714 - val_loss: 0.0649 - val_accuracy: 0.9778\n",
            "Epoch 246/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0862 - accuracy: 0.9619 - val_loss: 0.0768 - val_accuracy: 0.9778\n",
            "Epoch 247/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0953 - accuracy: 0.9810 - val_loss: 0.0579 - val_accuracy: 0.9778\n",
            "Epoch 248/250\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1320 - accuracy: 0.9429 - val_loss: 0.0893 - val_accuracy: 0.9778\n",
            "Epoch 249/250\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.9714 - val_loss: 0.1028 - val_accuracy: 0.9778\n",
            "Epoch 250/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0991 - accuracy: 0.9524 - val_loss: 0.0619 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(xtest,ytest) #akurasi data testing\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ME7yLIGPOHty",
        "outputId": "9eb2e7f5-2f51-49cc-887c-e8ac7b481e72"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0619 - accuracy: 1.0000\n",
            "\n",
            "accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = model.predict(xtest)"
      ],
      "metadata": {
        "id": "NkMVGz3hOND7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix #data training\n",
        "cm = confusion_mtx = confusion_matrix(ytest.argmax(axis=1), test_pred.argmax(axis=1))\n",
        "\n",
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6ABkWbbOPXX",
        "outputId": "069a9d1b-2231-404b-9732-84a4c170b91b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14,  0,  0],\n",
              "       [ 0, 18,  0],\n",
              "       [ 0,  0, 13]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm_df = pd.DataFrame(cm)                      \n",
        "plt.figure(figsize=(10,6)) \n",
        "sns.heatmap(cm_df, annot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "mbbGvUfqOUub",
        "outputId": "4a7f6054-9e94-4057-da1f-aca5046b9633"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5527621e90>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(ytest.argmax(axis=1), test_pred.argmax(axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-OW9EZ1OVOU",
        "outputId": "78b109b1-dff7-43c5-e0a7-e9c9a4fc00e6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        14\n",
            "           1       1.00      1.00      1.00        18\n",
            "           2       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n"
          ]
        }
      ]
    }
  ]
}